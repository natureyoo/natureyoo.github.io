<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jayeon Yoo</title>

    <meta name="author" content="Jayeon Yoo">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jayeon Yoo
                </p>
                <p>I am currently a Ph.D. candidate majoring in <a href="https://convergence.snu.ac.kr/page/intl_inf_intro.php">Intelligence Information Convergence Studies</a> at <a href="https://www.snu.ac.kr/index.html">Seoul National University</a>. I am advised by Prof. <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>, as a member of <a href="http://mipal.snu.ac.kr/index.php/Main_Page">Machine Intelligence and Pattern Analysis Lab (MIPAL)</a>. Prior to my graduate studies, I earned my Bachelor's degree in <a href="https://ime.postech.ac.kr/en/">Industrial and Management Engineering</a> from <a href="https://www.postech.ac.kr/eng/">POSTECH</a>.
                </p>
                <p>

                </p>
                <p style="text-align:center">
                  <a href="mailto:jayeon.yoo@snu.ac.kr">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV_JayeonYoo.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=JAeV59wAAAAJ&hl=ko">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/natureyoo/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/jayeon.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/jayeon.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I am deeply passionate about advancing deep learning models in demanding real-world scenarios, distinct from conventional training environments. With a solid background in Unsupervised Domain Adaptation, Test-Time Adaptation, and Open-set tasks, I tackle key challenges such as data distribution variations and exploiting unlabeled data. My goal is to improve the adaptability and versatility of deep learning models, ensuring they can effectively tackle new and evolving tasks with efficiency.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/ttaod.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="">
          <span class="papertitle">What, How, and When Should Object Detectors Update in Continually Changing Test Domains?</span>
        </a>
        <br>
		<strong>Jayeon Yoo</strong>,
		<a href="https://scholar.google.com/citations?user=J9r33w8AAAAJ&hl=ko">Dongkwan Lee</a>,
		<a href="https://scholar.google.com/citations?user=6bFY9FgAAAAJ&hl=ko">Inseop Chung</a>,
		<a href="https://utl.korea.ac.kr/team/">Donghyun Kim</a>,
		<a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>,
        <br>
        <em>CVPR</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2312.08875">paper</a>
        /
        <a href="https://github.com/natureyoo/ContinualTTA_ObjectDetection">code</a>
        <p></p>
        <p>
        Leveraging an adaptor module and an adaptation skipping strategy, our approach enables efficient object detector adaptation to dynamic test environments, improving detection performance, preventing catastrophic forgetting and maintaining high efficiency.
        </p>
      </td>
    </tr>
	
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/proxydet.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="">
          <span class="papertitle">ProxyDet: Synthesizing Proxy Novel Classes via Classwise Mixup for Open Vocabulary Object Detection</span>
        </a>
        <br>
		<a href="https://bestdeveloper691.github.io/">Joonhyun Jeong</a>,
		<a href="https://mli.kaist.ac.kr/people/geondo-park/">Geondo Park</a>,
		<a href="https://scholar.google.com/citations?user=-Be-Fz4AAAAJ&hl=ko">Hyungsik Jung</a>,
		<a href="https://scholar.google.com/citations?user=q_bEyHQAAAAJ&hl=ko">Heesu Kim</a>,
        <br>
        <em>AAAI</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2312.07266">paper</a>
        <p></p>
        <p>
        Enhancing open-vocabulary object detection through the proxy of novel classes via a convex combination in the CLIP embedding space.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/shot.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="">
          <span class="papertitle">SHOT: Suppressing the Hessian along the Optimization Trajectory for Gradient-Based Meta-Learning</span>
        </a>
        <br>
		<a>JunHoo Lee</a>,
		<strong>Jayeon Yoo</strong>,
		<a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>,
        <br>
        <em>NeurIPS</em>, 2023
        <br>
        <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/c1cdf3236050ad902c6581458e55f0c5-Abstract-Conference.html">paper</a>
        /
        <a href="https://github.com/JunHoo-Lee/SHOT">code</a>
        <p></p>
        <p>
        By hypothesizing that suppressing the Hessian enhances gradient-based meta-learning, an algorithm is introduced that improves few-shot learning performance with minimal added computational complexity, demonstrating broad applicability and efficacy.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/FindingEfficientPruning.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="">
          <span class="papertitle">Finding Efficient Pruned Network via Refined Gradients for Pruned Weights</span>
        </a>
        <br>
		<a href="https://sites.google.com/view/ml-pr/people?authuser=0">Jangho Kim</a>,
		<strong>Jayeon Yoo</strong>,
		<a href="https://ldynx.github.io/">Yeji Song</a>,
		<a href="https://scholar.google.co.kr/citations?user=S93OUYQAAAAJ&hl=ko">KiYoon Yoo</a>,
		<a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>,
        <br>
        <em>ACM MM</em>, 2023
        <br>
        <a href="https://arxiv.org/abs/2109.04660">paper</a>
        /
        <a href="https://github.com/Jangho-Kim/DCIL-pytorch">code</a>
        <p></p>
        <p>
        By introducing refined gradients for pruned weights, our Dynamic Collective Intelligence Learning approach significantly enhances performance and training stability in deep neural networks at high sparsity levels.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/da_semantic_segmentation.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="">
          <span class="papertitle">Exploiting inter-pixel correlations in unsupervised domain adaptation for semantic segmentation</span>
        </a>
        <br>
		<a href="https://scholar.google.com/citations?user=6bFY9FgAAAAJ&hl=ko">Inseop Chung</a>,
		<strong>Jayeon Yoo</strong>,
		<a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>,
        <br>
        <em>WACV Workshops </em>, 2023
        <br>
        <a href="https://openaccess.thecvf.com/content/WACV2023W/RWS/html/Chung_Exploiting_Inter-Pixel_Correlations_in_Unsupervised_Domain_Adaptation_for_Semantic_Segmentation_WACVW_2023_paper.html">paper</a>
        <p></p>
        <p>
          Transferring inter-pixel correlations from source to target domain using a self-attention module, which captures domain-invariant properties, significantly improves adaptation for semantic segmentation, notably enhancing performance for rare or small-region classes.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/oada.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="">
          <span class="papertitle">Unsupervised Domain Adaptation for One-stage Object Detector using Offsets to Bounding Box</span>
        </a>
        <br>
		<strong>Jayeon Yoo</strong>,
		<a href="https://scholar.google.com/citations?user=6bFY9FgAAAAJ&hl=ko">Inseop Chung</a>,
		<a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>,
        <br>
        <em>ECCV</em>, 2022
        <br>
        <a href="https://arxiv.org/pdf/2207.09656">paper</a>
        <p></p>
        <p>
          By analyzing a unique characteristic of object detection—features distributed by both object class and regression values—we effectively adapt object detectors to the target domain, taking into account these regression values to mitigate negative transfer and improve adaptation performance.
        </p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/vos.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="">
          <span class="papertitle">Learning dynamic network using a reuse gate function in semi-supervised video object segmentation</span>
        </a>
        <br>
		<a href="https://scholar.google.com/citations?user=-z-O5AIAAAAJ&hl=ko">Hyojin Park</a>,
		<strong>Jayeon Yoo</strong>,
		<a href="https://scholar.google.com/citations?user=CybfMgUAAAAJ&hl=ko&oi=ao">Seohyeong Jeong</a>,
		<a href="https://scholar.google.com/citations?user=G7oHjssAAAAJ&hl=ko&oi=ao">Ganesh Venkatesh</a>,
		<a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>,
        <br>
        <em>CVPR</em>, 2021
        <br>
        <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Park_Learning_Dynamic_Network_Using_a_Reuse_Gate_Function_in_Semi-Supervised_CVPR_2021_paper.pdf">paper</a>
        /
        <a href="https://github.com/HYOJINPARK/Reuse_VOS">code</a>
        <p></p>
        <p>

Leveraging temporal information to discern frames with minimal change, a novel dynamic network is proposed for Semi-supervised Video Object Segmentation, significantly boosting inference speed with negligible accuracy loss by selectively bypassing intensive mask generation for static or slow-moving scenes across various datasets.
        </p>
      </td>
    </tr>

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
